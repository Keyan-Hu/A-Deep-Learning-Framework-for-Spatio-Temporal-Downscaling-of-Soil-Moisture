{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Starting train for epoch 0\n",
      "Epoch 0:   0%|          | 0/1168 [00:00<?, ?it/s]c:\\Anaconda\\envs\\MLL\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "Epoch 0: 100%|██████████| 1168/1168 [00:52<00:00, 22.19it/s]\n",
      "INFO: Epoch 0 Average Loss: nan\n",
      "INFO: Starting train for epoch 1\n",
      "Epoch 1:  24%|██▍       | 278/1168 [00:06<00:19, 44.85it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 106\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# set random seed to make the experiment reproducible\u001b[39;00m\n\u001b[0;32m    105\u001b[0m Util\u001b[38;5;241m.\u001b[39mrandom_seed(SEED\u001b[38;5;241m=\u001b[39mHyperparameter_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_seed\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 106\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 97\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     95\u001b[0m path_config \u001b[38;5;241m=\u001b[39m Util\u001b[38;5;241m.\u001b[39mload_config(args\u001b[38;5;241m.\u001b[39mpath_config_path)\n\u001b[0;32m     96\u001b[0m logger \u001b[38;5;241m=\u001b[39m setup_logger(path_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 74\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(path_dict, Hyperparameter_dict, logger)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# 训练\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Hyperparameter_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m     73\u001b[0m     model, optimizer, grad_scaler, total_step\u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m---> 74\u001b[0m     \u001b[43mtrain_val\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_improved_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_improved_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarmup_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_scaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_grad_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_collection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_collection\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHyperparameter_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpatience\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHyperparameter_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfactor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtotal_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_up_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHyperparameter_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwarm_up_step\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# 评估\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39mHyperparameter_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluate_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\Desktop\\code\\LSTM\\LSTM\\train\\train_val.py:36\u001b[0m, in \u001b[0;36mtrain_val\u001b[1;34m(mode, model, dataloader, epoch, non_improved_epoch, best_metrics, device, warmup_lr, grad_scaler, logger, max_grad_norm, criterion, metric_collection, patience, optimizer, checkpoint_path, factor, save_interval, save_checkpoint, total_step, warm_up_step, mean, std)\u001b[0m\n\u001b[0;32m     33\u001b[0m         param_group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m warmup_lr[total_step]\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39mgrad_scaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 36\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m     38\u001b[0m     output \u001b[38;5;241m=\u001b[39m output \u001b[38;5;241m*\u001b[39m std \u001b[38;5;241m+\u001b[39m mean\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\MLL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\MLL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\code\\LSTM\\LSTM\\model\\LSTM.py:29\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 29\u001b[0m     x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m     31\u001b[0m     x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm2(x)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\MLL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\MLL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\MLL\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:879\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    876\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    882\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    883\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\Administrator\\Desktop\\code\\LSTM\\LSTM\")\n",
    "from model.LSTM import LSTMModel, BiLSTMModel\n",
    "from log.logging import setup_logger\n",
    "from utils.utils import Util\n",
    "from dataset.Dataset import LSTMDataset\n",
    "from metrics.metrics import CustomMetricCollection, CustomRMSELoss\n",
    "from train_val import train_val, test\n",
    "\n",
    "def train(path_dict, Hyperparameter_dict, logger):\n",
    "    dataset = LSTMDataset(\"D:\\Data_Store\\Dataset\\exp\\data_batch_0.npy\")\n",
    "\n",
    "    # 使用您自定义的split_dataset函数划分数据集\n",
    "    train_dataset, val_dataset, test_dataset = Util.split_dataset(dataset, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15)\n",
    "    loader_args = dict(\n",
    "        num_workers=1,                # 使用的工作进程数量\n",
    "        prefetch_factor=5,            # 数据预取的因子\n",
    "        persistent_workers=True       # 是否使用持久化工作进程\n",
    "    )\n",
    "        # 使用 DataLoader 加载数据集\n",
    "    train_loader = DataLoader(train_dataset, batch_size=Hyperparameter_dict['batch_size'], \\\n",
    "                              shuffle=True, drop_last=False, **loader_args)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=Hyperparameter_dict['batch_size'], \\\n",
    "                            shuffle=False, drop_last=False, **loader_args)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=Hyperparameter_dict['batch_size'], \\\n",
    "                             shuffle=False, drop_last=False, **loader_args)\n",
    "\n",
    "    model = LSTMModel(input_dim=Hyperparameter_dict['input_dim'], hidden_size=Hyperparameter_dict['hidden_size'],dropout_rate=Hyperparameter_dict['dropout_rate'])\n",
    "    \n",
    "    # 设定设备\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 加载mean和std\n",
    "    mean = np.load(path_dict['mean'])[0]\n",
    "    std = np.load(path_dict['std'])[0]\n",
    "    # 设置优化器\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=Hyperparameter_dict['learning_rate'], weight_decay=Hyperparameter_dict['weight_decay'])  # 优化器\n",
    "    warmup_lr = np.arange(1e-7, Hyperparameter_dict['learning_rate'], (Hyperparameter_dict['learning_rate'] - 1e-7) / Hyperparameter_dict['warm_up_step'])\n",
    "    grad_scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    # 如果设置了加载预训练模型的标志\n",
    "    '''\n",
    "    if path_dict['LSTM_Best_Model']:\n",
    "        checkpoint = torch.load(path_dict['LSTM_Best_Model'], map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state'])\n",
    "        if 'optimizer' in checkpoint and optimizer:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "        logging.info(f'Model loaded from {path_dict[\"LSTM_Best_Model\"]}')\n",
    "    '''\n",
    "    # 初始化自定义指标收集器\n",
    "    metric_collection = CustomMetricCollection()\n",
    "    # 初始化最佳评估指标字典\n",
    "    best_metrics = dict.fromkeys(['best_RMSE', 'best_loss'], 1)  # 最佳评估指标\n",
    "    # 初始化非改进的时期计数\n",
    "    non_improved_epoch = 0  # 当non_improved_epoch等于patience时，调整学习率\n",
    "    # 损失函数\n",
    "    criterion = CustomRMSELoss()\n",
    "    # 定义总步数\n",
    "    total_step = 0\n",
    "\n",
    "    # 训练\n",
    "    for epoch in range(Hyperparameter_dict[\"epochs\"]):\n",
    "        model, optimizer, grad_scaler, total_step= \\\n",
    "        train_val(mode='train', model=model, dataloader=train_loader, \n",
    "                epoch=epoch, non_improved_epoch=non_improved_epoch,device=device, warmup_lr=warmup_lr, grad_scaler=grad_scaler,\n",
    "                max_grad_norm=20, criterion=criterion, metric_collection=metric_collection,patience=Hyperparameter_dict['patience'],\n",
    "                optimizer=optimizer, factor=Hyperparameter_dict['factor'],mean = mean, std = std,\n",
    "                total_step=total_step, warm_up_step=Hyperparameter_dict['warm_up_step'], logger=logger)\n",
    "        \n",
    "        # 评估\n",
    "        if epoch>=Hyperparameter_dict[\"evaluate_epoch\"]:\n",
    "            with torch.no_grad():\n",
    "                model, optimizer, best_metrics, non_improved_epoch, epoch_loss,total_step\\\n",
    "                = train_val(mode='val', model=model, dataloader=val_loader, \n",
    "                        epoch=epoch, non_improved_epoch=non_improved_epoch, best_metrics=best_metrics,\n",
    "                        device=device, warmup_lr=warmup_lr,max_grad_norm=20, criterion=criterion, metric_collection=metric_collection,patience=Hyperparameter_dict['patience'],\n",
    "                        optimizer=optimizer,checkpoint_path=path_dict['LSTM_check_point_Model'], factor=Hyperparameter_dict['factor'],\n",
    "                        save_interval=Hyperparameter_dict['save_interval'], save_checkpoint=Hyperparameter_dict['save_checkpoint'],\n",
    "                        total_step=total_step, warm_up_step=Hyperparameter_dict['warm_up_step'],logger=logger,mean = mean, std = std)\n",
    "\n",
    "    average_metrics = test(model=model, dataloader=test_loader, criterion=criterion,metric_collection=metric_collection, device=device, logger=logger,mean = mean, std = std)\n",
    "\n",
    "def main(args):\n",
    "    model_config = Util.load_config(args.model_config_path)\n",
    "    path_config = Util.load_config(args.path_config_path)\n",
    "    logger = setup_logger(path_config['log'])\n",
    "    return train(path_config, model_config, logger)\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model_config_path', type=str, default='../config/model_config.yaml')\n",
    "    parser.add_argument('--path_config_path', type=str, default='../config/path_config.yaml')\n",
    "    args = parser.parse_known_args()[0]\n",
    "    Hyperparameter_dict = Util.load_config(args.model_config_path)\n",
    "    # set random seed to make the experiment reproducible\n",
    "    Util.random_seed(SEED=Hyperparameter_dict['random_seed'])\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(344379, 57, 42)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 加载 .npy 文件\n",
    "data = np.load(\"D:\\\\Data_Store\\\\Dataset\\\\LSTM\\\\data_batch_1.npy\")\n",
    "\n",
    "print(data.shape)\n",
    "data = data[:,-1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载mean和std\n",
    "mean = np.load(r\"D:\\Data_Store\\Dataset\\LSTM\\Nor\\mean.npy\")[0]\n",
    "std = np.load(r\"D:\\Data_Store\\Dataset\\LSTM\\Nor\\std.npy\")[0]\n",
    "\n",
    "data = data*std+mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
